{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/craigcalzado/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define categories\n",
    "categories = [\"business\", \"sports\", \"technology\", \"entertainment\"]\n",
    "\n",
    "# use get_all_new_article function from acquire.py file \n",
    "\n",
    "news_df = acquire.get_all_news_articles(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rupee closes at all-time low of 77.50 against ...</td>\n",
       "      <td>The Indian rupee weakened further on Monday to...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When are you coming to deliver 1st Tesla? Payt...</td>\n",
       "      <td>Paytm CEO Vijay Shekhar Sharma took to Twitter...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Layout of 'world's first Bitcoin City' in El S...</td>\n",
       "      <td>El Salvador's President Nayib Bukele has share...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bitcoin briefly drops below $30,000 for first ...</td>\n",
       "      <td>Bitcoin, in the early hours of Tuesday, fell b...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Musk's $44 bn Twitter deal at risk of being re...</td>\n",
       "      <td>Elon Musk's $44 billion offer to buy Twitter c...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Rupee closes at all-time low of 77.50 against ...   \n",
       "1  When are you coming to deliver 1st Tesla? Payt...   \n",
       "2  Layout of 'world's first Bitcoin City' in El S...   \n",
       "3  Bitcoin briefly drops below $30,000 for first ...   \n",
       "4  Musk's $44 bn Twitter deal at risk of being re...   \n",
       "\n",
       "                                             content  category  \n",
       "0  The Indian rupee weakened further on Monday to...  business  \n",
       "1  Paytm CEO Vijay Shekhar Sharma took to Twitter...  business  \n",
       "2  El Salvador's President Nayib Bukele has share...  business  \n",
       "3  Bitcoin, in the early hours of Tuesday, fell b...  business  \n",
       "4  Elon Musk's $44 billion offer to buy Twitter c...  business  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the head of dataframe\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Indian rupee weakened further on Monday to close at a new all-time low of 77.50 against the US dollar, 60 paise over its previous close. During the trading session, the rupee touched its lifetime low of 77.52. The currency was weighed down by elevated crude oil prices and a widening trade deficit.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets use the content of first news item as 'article' to test my functions\n",
    "\n",
    "article = news_df.content[0]\n",
    "article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:\n",
    "\n",
    "- Lowercase everything\n",
    "- Normalize unicode characters\n",
    "- Replace anything that is not a letter, number, whitespace or a single quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(string):\n",
    "    '''\n",
    "    This function takes in a string and\n",
    "    returns the string normalized.\n",
    "    '''\n",
    "    string = unicodedata.normalize('NFKD', string)\\\n",
    "             .encode('ascii', 'ignore')\\\n",
    "             .decode('utf-8', 'ignore')\n",
    "    string = re.sub(r'[^\\w\\s]', '', string).lower()\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the function to clean the article\n",
    "article_clean = basic_clean(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the indian rupee weakened further on monday to close at a new alltime low of 7750 against the us dollar 60 paise over its previous close during the trading session the rupee touched its lifetime low of 7752 the currency was weighed down by elevated crude oil prices and a widening trade deficit'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the cleaned article\n",
    "article_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Define a function named tokenize. It should take in a string and tokenize all the words in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(string):\n",
    "    '''\n",
    "    This function takes in a string and returns a tokenized string.\n",
    "    \n",
    "    '''\n",
    "    # create the tokenizer\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    # Use the tokenizer\n",
    "    string = tokenizer.tokenize(string, return_str=True)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Indian rupee weakened further on Monday to close at a new all-time low of 77.50 against the US dollar , 60 paise over its previous close. During the trading session , the rupee touched its lifetime low of 77.52. The currency was weighed down by elevated crude oil prices and a widening trade deficit .'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the function defined above\n",
    "\n",
    "tokenize(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Define a function named stem. It should accept some text and return the text after applying stemming to all the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(string):\n",
    "    '''\n",
    "    This function takes in a string and\n",
    "    returns a string with words stemmed.\n",
    "    '''\n",
    "    # Create porter stemmer.\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    \n",
    "    # Use the stemmer to stem each word in the list of words we created by using split.\n",
    "    stems = [ps.stem(word) for word in string.split()]\n",
    "    \n",
    "    # Join our lists of words into a string again and assign to a variable.\n",
    "    string = ' '.join(stems)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the indian rupe weaken further on monday to close at a new all-tim low of 77.50 against the us dollar, 60 pais over it previou close. dure the trade session, the rupe touch it lifetim low of 77.52. the currenc wa weigh down by elev crude oil price and a widen trade deficit.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the function defined above\n",
    "stem(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/craigcalzado/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(string):\n",
    "    '''\n",
    "    This function takes in string for and\n",
    "    returns a string with words lemmatized.\n",
    "    '''\n",
    "    # Create the lemmatizer.\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "    # Use the lemmatizer on each word in the list of words we created by using split.\n",
    "    lemmas = [wnl.lemmatize(word) for word in string.split()]\n",
    "    \n",
    "    # Join our list of words into a string again and assign to a variable.\n",
    "    string = ' '.join(lemmas)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Indian rupee weakened further on Monday to close at a new all-time low of 77.50 against the US dollar, 60 paisa over it previous close. During the trading session, the rupee touched it lifetime low of 77.52. The currency wa weighed down by elevated crude oil price and a widening trade deficit.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the function defined above\n",
    "lemmatize(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function should define two optional parameters, extra_words and exclude_words.\n",
    "\n",
    "These parameters should define any additional stop words to include, and any words that we don't want to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(string, extra_words = [], exclude_words = []):\n",
    "    '''\n",
    "    This function takes in a string, optional extra_words and exclude_words parameters\n",
    "    with default empty lists and returns a string.\n",
    "    '''\n",
    "    # Create stopword_list.\n",
    "    stopword_list = stopwords.words('english')\n",
    "    \n",
    "    # Remove 'exclude_words' from stopword_list to keep these in my text.\n",
    "    stopword_list = set(stopword_list) - set(exclude_words)\n",
    "    \n",
    "    # Add in 'extra_words' to stopword_list.\n",
    "    stopword_list = stopword_list.union(set(extra_words))\n",
    "    \n",
    "    # Split words in string.\n",
    "    words = string.split()\n",
    "    \n",
    "    # Create a list of words from my string with stopwords removed and assign to variable.\n",
    "    filtered_words = [word for word in words if word not in stopword_list]\n",
    "    \n",
    "    # Join words in the list back into strings and assign to a variable.\n",
    "    string_without_stopwords = ' '.join(filtered_words)\n",
    "    \n",
    "    return string_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Indian rupee weakened Monday close new all-time low 77.50 US dollar, 60 paise previous close. During trading session, rupee touched lifetime low 77.52. The currency weighed elevated crude oil prices widening trade deficit.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the function defined above\n",
    "remove_stopwords(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Use your data from the acquire to produce a dataframe of the news articles. Name the dataframe news_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rupee closes at all-time low of 77.50 against ...</td>\n",
       "      <td>The Indian rupee weakened further on Monday to...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When are you coming to deliver 1st Tesla? Payt...</td>\n",
       "      <td>Paytm CEO Vijay Shekhar Sharma took to Twitter...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Layout of 'world's first Bitcoin City' in El S...</td>\n",
       "      <td>El Salvador's President Nayib Bukele has share...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bitcoin briefly drops below $30,000 for first ...</td>\n",
       "      <td>Bitcoin, in the early hours of Tuesday, fell b...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Musk's $44 bn Twitter deal at risk of being re...</td>\n",
       "      <td>Elon Musk's $44 billion offer to buy Twitter c...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Rupee closes at all-time low of 77.50 against ...   \n",
       "1  When are you coming to deliver 1st Tesla? Payt...   \n",
       "2  Layout of 'world's first Bitcoin City' in El S...   \n",
       "3  Bitcoin briefly drops below $30,000 for first ...   \n",
       "4  Musk's $44 bn Twitter deal at risk of being re...   \n",
       "\n",
       "                                             content  category  \n",
       "0  The Indian rupee weakened further on Monday to...  business  \n",
       "1  Paytm CEO Vijay Shekhar Sharma took to Twitter...  business  \n",
       "2  El Salvador's President Nayib Bukele has share...  business  \n",
       "3  Bitcoin, in the early hours of Tuesday, fell b...  business  \n",
       "4  Elon Musk's $44 billion offer to buy Twitter c...  business  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check news_df dataframe:\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     indian rupee weakened monday close new alltime...\n",
       "1     paytm ceo vijay shekhar sharma took twitter re...\n",
       "2     el salvador president nayib bukele ha shared l...\n",
       "3     bitcoin early hour tuesday fell 30000 first ti...\n",
       "4     elon musk 44 billion offer buy twitter could g...\n",
       "                            ...                        \n",
       "95    actress mrunal thakur speaking 10 year acting ...\n",
       "96    actor abhishek bachchan led star football club...\n",
       "97    doctor strange multiverse madness screenwriter...\n",
       "98    actress sarika said ran money covid19 pandemic...\n",
       "99    actor sanjay dutt revealed also whistled yashs...\n",
       "Name: content, Length: 100, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use all the functions to see if they work on news_df's content column\n",
    "\n",
    "news_df['content'].apply(basic_clean)\\\n",
    ".apply(tokenize)\\\n",
    ".apply(lemmatize)\\\n",
    ".apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Make another dataframe for the Codeup blog posts. Name the dataframe codeup_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/00/hwmfmnz96wxfytp1bbw2qlym0000gn/T/ipykernel_96082/2927478013.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcodeup_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macquire\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_blogs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/repos/codeup-data-science/natural-language-processing-exercises/acquire.py\u001b[0m in \u001b[0;36mget_blogs\u001b[0;34m()\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0mlist_of_blog_dicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcodeup_blog_urls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mlist_of_blog_dicts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macquire_codeup_blog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_of_blog_dicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/codeup-data-science/natural-language-processing-exercises/acquire.py\u001b[0m in \u001b[0;36macquire_codeup_blog\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;31m# grab all unformatted paragraphs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0mparagraphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'div'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'et_pb_module et_pb_post_content et_pb_post_content_0_tb_body'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'p'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# codeup_df = acquire.get_blogs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codeup_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. For each dataframe, produce the following columns:\n",
    "\n",
    "- title to hold the title\n",
    "- original to hold the original article/post content\n",
    "- clean to hold the normalized and tokenized original with the stopwords removed.\n",
    "- stemmed to hold the stemmed version of the cleaned data.\n",
    "- lemmatized to hold the lemmatized version of the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_article_data(df, column, extra_words=[], exclude_words=[]):\n",
    "    '''\n",
    "    This function take in a df and the string name for a text column with \n",
    "    option to pass lists for extra_words and exclude_words and\n",
    "    returns a df with the text article title, original text, stemmed text,\n",
    "    lemmatized text, cleaned, tokenized, & lemmatized text with stopwords removed.\n",
    "    '''\n",
    "    df['clean'] = df[column].apply(basic_clean)\\\n",
    "                            .apply(tokenize)\\\n",
    "                            .apply(remove_stopwords, \n",
    "                                   extra_words=extra_words, \n",
    "                                   exclude_words=exclude_words)\n",
    "    \n",
    "    df['stemmed'] = df[column].apply(basic_clean)\\\n",
    "                            .apply(tokenize)\\\n",
    "                            .apply(stem)\\\n",
    "                            .apply(remove_stopwords, \n",
    "                                   extra_words=extra_words, \n",
    "                                   exclude_words=exclude_words)\n",
    "    \n",
    "    df['lemmatized'] = df[column].apply(basic_clean)\\\n",
    "                            .apply(tokenize)\\\n",
    "                            .apply(lemmatize)\\\n",
    "                            .apply(remove_stopwords, \n",
    "                                   extra_words=extra_words, \n",
    "                                   exclude_words=exclude_words)\n",
    "    \n",
    "    return df[['title', column,'clean', 'stemmed', 'lemmatized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rupee closes at all-time low of 77.50 against ...</td>\n",
       "      <td>The Indian rupee weakened further on Monday to...</td>\n",
       "      <td>indian rupee weakened monday close new alltime...</td>\n",
       "      <td>indian rupe weaken monday close new alltim low...</td>\n",
       "      <td>indian rupee weakened monday close new alltime...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When are you coming to deliver 1st Tesla? Payt...</td>\n",
       "      <td>Paytm CEO Vijay Shekhar Sharma took to Twitter...</td>\n",
       "      <td>paytm ceo vijay shekhar sharma took twitter re...</td>\n",
       "      <td>paytm ceo vijay shekhar sharma took twitter re...</td>\n",
       "      <td>paytm ceo vijay shekhar sharma took twitter re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Layout of 'world's first Bitcoin City' in El S...</td>\n",
       "      <td>El Salvador's President Nayib Bukele has share...</td>\n",
       "      <td>el salvadors president nayib bukele shared lay...</td>\n",
       "      <td>el salvador presid nayib bukel share layout wo...</td>\n",
       "      <td>el salvador president nayib bukele shared layo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bitcoin briefly drops below $30,000 for first ...</td>\n",
       "      <td>Bitcoin, in the early hours of Tuesday, fell b...</td>\n",
       "      <td>bitcoin early hours tuesday fell 30000 first t...</td>\n",
       "      <td>bitcoin earli hour tuesday fell 30000 first ti...</td>\n",
       "      <td>bitcoin early hour tuesday fell 30000 first ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Musk's $44 bn Twitter deal at risk of being re...</td>\n",
       "      <td>Elon Musk's $44 billion offer to buy Twitter c...</td>\n",
       "      <td>elon musks 44 billion offer buy twitter could ...</td>\n",
       "      <td>elon musk 44 billion offer buy twitter could g...</td>\n",
       "      <td>elon musk 44 billion offer buy twitter could g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Rupee closes at all-time low of 77.50 against ...   \n",
       "1  When are you coming to deliver 1st Tesla? Payt...   \n",
       "2  Layout of 'world's first Bitcoin City' in El S...   \n",
       "3  Bitcoin briefly drops below $30,000 for first ...   \n",
       "4  Musk's $44 bn Twitter deal at risk of being re...   \n",
       "\n",
       "                                             content  \\\n",
       "0  The Indian rupee weakened further on Monday to...   \n",
       "1  Paytm CEO Vijay Shekhar Sharma took to Twitter...   \n",
       "2  El Salvador's President Nayib Bukele has share...   \n",
       "3  Bitcoin, in the early hours of Tuesday, fell b...   \n",
       "4  Elon Musk's $44 billion offer to buy Twitter c...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  indian rupee weakened monday close new alltime...   \n",
       "1  paytm ceo vijay shekhar sharma took twitter re...   \n",
       "2  el salvadors president nayib bukele shared lay...   \n",
       "3  bitcoin early hours tuesday fell 30000 first t...   \n",
       "4  elon musks 44 billion offer buy twitter could ...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  indian rupe weaken monday close new alltim low...   \n",
       "1  paytm ceo vijay shekhar sharma took twitter re...   \n",
       "2  el salvador presid nayib bukel share layout wo...   \n",
       "3  bitcoin earli hour tuesday fell 30000 first ti...   \n",
       "4  elon musk 44 billion offer buy twitter could g...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  indian rupee weakened monday close new alltime...  \n",
       "1  paytm ceo vijay shekhar sharma took twitter re...  \n",
       "2  el salvador president nayib bukele shared layo...  \n",
       "3  bitcoin early hour tuesday fell 30000 first ti...  \n",
       "4  elon musk 44 billion offer buy twitter could g...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the function defined above for news_df's content column.\n",
    "\n",
    "prep_article_data(news_df, 'content', extra_words = ['ha'], exclude_words = ['no']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ask yourself:\n",
    "\n",
    "- If your corpus is 493KB, would you prefer to use stemmed or lemmatized text?\n",
    "\n",
    "I would lemmatize it so that the words that are returned are real words. The dataset is small, so I don't see a waste of resources doing this method over stemming\n",
    "\n",
    "- If your corpus is 25MB, would you prefer to use stemmed or lemmatized text?\n",
    "\n",
    "I would still lemmatize it...25MB isn't to large\n",
    "\n",
    "- If your corpus is 200TB of text and you're charged by the megabyte for your hosted computational resources, would you prefer to use stemmed or lemmatized text?\n",
    "\n",
    "Stemmed, I'll work with what I get before I have to pay, would be very expensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
